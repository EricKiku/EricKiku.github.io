import{_ as p,W as r,X as n,a2 as o}from"./framework-61af4b36.js";const t={},s=o('<h2 id="选择题" tabindex="-1"><a class="header-anchor" href="#选择题" aria-hidden="true">#</a> 选择题</h2><p><strong>1.数据预处理方法有数据清理、数据集成、数据变换和 ( C )</strong></p><p>A 离散数据 B 数据清洗 C 数据规约 D 数据可视化</p><p><strong>2.Support(X-Y)&gt;=min sup 且 confidence(X-Y)min_conf，称关联规则 X一Y为( A )</strong></p><p>A 强关联规则 B 弱关联规则 C 频繁项集 D 大项目集</p><p><strong>3.决策树分类方法采用（ A ）的方式进行递归。</strong></p><p>A 自顶向下 B 自底向上 C 自左向右 D 自右向左</p><p><strong>4.贝叶斯方法是研究不确定性问题的方法，它研究的是 ( B ) 问题</strong></p><p>A 经典概率 B 主观概率 C 聚类 D 关联规则.</p><p><strong>5.下列不属于层次聚类算法的是 ( D )</strong></p><p>A BIRCH 算法 B CURE 算法</p><p>C ROCK 算法 D k-means 算法</p><p><strong>6.数据挖掘的目的是 ( A )</strong></p><p>A. 从数据中发现模式和规律 B. 从数据中提取全部信息 C. 对数据进行完整的描述 D.对数据进行分类和归纳</p><p><strong>7.根据信息增益来构造来构造决策树的算法是 ( A )</strong></p><p>A ID3 决策树</p><p>B 递归.</p><p>C 归约 D FIFO</p><p><strong>8.数据归约的方法有 ( D )</strong></p><p>A 维归约</p><p>B 数量规约</p><p>C 数据压缩</p><p>D 以上都是</p><p><strong>9.根据特征选择过程与后续数据挖掘算法的关联，特征选择方法可分为过滤、封装和 ( B )。</strong></p><p>A 整合 B 嵌入 C 分配 D 选择</p><p><strong>10.中心趋势度量不包括 ( B )。</strong></p><p>A 均值 (mean)</p><p>B 四分位数(quartiles)</p><p>C 众数(mode)</p><p>D 中列数(midrange)</p><blockquote><p>1-5 C A A B D</p><p>6-10 A A D B B</p></blockquote><p><strong>1.下列不属于卷积神经网络(CNN)的是( C )。</strong></p><p>A 输入层 B 卷积层</p><p>C 逻辑层</p><p>D 池化层</p><p><strong>2.Support(X一Y)&gt;=min_sup 且 confidence(X-Y)min_conf，称关联规则 X-&gt;Y为( A)</strong></p><p>A 强关联规则 B 弱关联规则 C 频繁项集 D 大项目集</p><p><strong>3. C4.5 使用 ( A )作为属性选择标准</strong></p><p>A 信息增益率</p><p>B 信息增益</p><p>C 熵</p><p>D Gini 系数</p><p><strong>4.信息检索指的是从( )的集合中找出满足需求的( B ) 的过程。</strong></p><p>A.文本;单词</p><p>B.文本;文档</p><p>C 文档;单词</p><p>D.文档;文本</p><p><strong>5.下列不属于层次聚类算法的是（ D ）</strong></p><p>A BIRCH 算法 B CURE算法 C ROCK 算法 D k-means 算法</p><p><strong>6.数据挖掘的目的是( A )。</strong></p><p>A. 从数据中发现模式和规律 B. 从数据中提取全部信息 C. 对数据进行完整的描述 D. 对数据进行分类和归纳</p><p><strong>7.下面哪个属于映射数据到新的空间的方法? ( A )</strong></p><p>A.傅立叶变换</p><p>B.特征加权</p><p>C.渐进抽样</p><p>D.维归约</p><p><strong>8.数据归约的方法有( D )。</strong></p><p>A 维归约</p><p>B 数量规约</p><p>C 数据压缩</p><p>D 以上都是</p><p><strong>9.下面不属于回归分析的是:( D )。</strong></p><p>A 线性回归 B 非线性回归 C 逻辑回归 D 离散类别值</p><p><strong>10.中心趋势度量不包括 ( B )。</strong></p><p>A 均值 (mean)</p><p>B 四分位数 (quartiles)</p><p>C 众数 (mode)</p><p>D 中列数(midrange)</p><blockquote><p>1-5 C A A B D 6-10 A A D D B</p></blockquote><h2 id="计算题" tabindex="-1"><a class="header-anchor" href="#计算题" aria-hidden="true">#</a> 计算题</h2><p>1.写出余弦相似度的计算公式并计算 d1 和 d2 的余弦相似度</p><p>d1= 3 2 0 5 0 0 0 2 0 0 d2= 1 0 0 0 0 0 0 1 0 2</p><p>2.求X，Y 的简单匹配系数 SMC 和 Jaccard 系数</p><p>X= ( 1 0 0 0 0 0 0 0 0 0) Y=( 0 0 0 0 0 0 1 0 0 1)</p><p>答:</p><figure><img src="http://39.98.110.164/wj.jpg" alt="image-20230606101028783" tabindex="0" loading="lazy"><figcaption>image-20230606101028783</figcaption></figure><h2 id="第三次月考答案" tabindex="-1"><a class="header-anchor" href="#第三次月考答案" aria-hidden="true">#</a> 第三次月考答案</h2><p>1、有监督;无监督 2、决策节点(内部节点); 分支; 叶节点 3、 4、生物神经网络;数据模型 5、项集的频数;支持度计数 6、维度;稀疏性:分辨率 7、前向网络:反馈网络: 层内有互连的网络 8、预测型任务;描述型任务 9、训练集;测试集</p><p>论述题：</p><p>1、<strong>ID3算法优缺点</strong></p><p>优点: 理论清晰，方法简单，学习能力较强</p><p>缺点: (1)算法只能处理分类属性数据，无法处理连续型数据:(2)算法对测试属性的每个取值相应产生一个分支，且划分相应的数据样本集,这样的划分会导致产生许多小的子集。随着子集被划分得越来越小，划分过程将会由于子集规模过小所造成的统计特征不充分而停止;(3)ID3 算法中使用信息增益作为决策树节点属性选择的标准，由于信息增益在类别值多的属性上计算结果大于类别值少的属性上计算结果，这将导致决策树算法偏向选择具有较多分枝的属性，因而可能导致过度拟合。在极端的情况下，如果某个属性对于训练集中的每个元组都有唯一的一个值，则认为该属性是最好的这是因为对于每个划分都只有一个元组(因此也是一类)。</p><p>2、<strong>线性回归和逻辑回归的区别</strong> (1)线性回归是计算出具体的值，是解决回归问题: 逻辑回归是给出是和否，解决的是分类问题。 (2)逻辑回归引入了 sigmoid 函数，把y 值从线性回归的(-∞,+∞ )限制到了 (0,1)的范围。 (3)逻辑回归通过值判断的方式，引入了非线性因素，可以处理分类问题，</p><p>3、<strong>引起空缺值的原因</strong> (1)设备异常 (2)与其他已有数据不一致而被删除 (3)因为误解而没有被输入的数据 (4)在输入数据时，有些数据认为得不到重视而没有被输入</p><p>(5)对数据的改变没有进行日志记载</p><p>4、<strong>K-近邻算法的优缺点</strong> 优点: (1)简单易于理解和实现。(2)对于较小的数据集效果较好。(3)对异常值不敏感(4)可以处理多分类问题, 缺点: (1)对大规模数据集计算复杂度高。(2)需要存储全部训练数据。(3)对特征缩放和特征选择较为敏感。(4)需要选择合适的 K 值，对结果影响较大</p><p>5、<strong>人工神经网络的特点和优越性</strong></p><p>(1)具有自学习功能。例如图像识别，只需先把不同的图像样板和对应的应识别的结果输入人工神经网终，网络就会通过自学习功能,慢慢学会识别类似的图像</p><p>(2)具有联想存储功能。人的大脑是具有联想功能的。用人工神经网络的反馈网终就可以实现这种联想。</p><p>(3)具有容错性。神经网络可以从不完善的数据图形进行学习和作出决定。由于知识存在于整个系统而不是一个存储单元中，一些结点不参与运算，对整个系统性能不会产生重大影响所以，神经网络承受硬件损坏的能力比一般计算机强得多。</p><p>(4)具有高速寻找优化解的能力。寻找一个复杂问题的优化解，往往需要很大的计算量，利用一个针对某问题而设计的反馈型人工神经网络，发挥计算机的高速运算能力，可能很快找到优化解。</p><p>6、<strong>分类的步骤</strong> (1)首先将数据集划分为 2 部分: 训练集和测试集</p><p>(2) 第一步: 对训练集学习，构建分类模型模型可以是决策树或分类规则等形式。</p><p>(3) 第二步:用建好的分类模型对测试集分类评估该分类模型的分类准确度及其它性能</p><p>(4)最后，使用分类准确度高的分类模型对类标号未知的未来样本数据进行分类</p><p>7、<strong>聚类和分类的主要区别</strong></p><p>(1) 聚类是一种无监督的学习算法，没有预先定义的类。而分类问题是有监督学习算法，预先定义有类 (2) 分类是训练样本包含有分类属性值，聚类则是在训练样本中找到这些分类属性值。 (3) 分类问题可以应用于建立预测模型，可以预测未来: 聚类问题则可以用于制定分组策略，发现数据内在的规律。</p><p><strong>阐述学习数据挖掘技术这门课程对将来学习生活的作用。</strong></p><p>(1) 预测: 通过建立模型来预测某些未来事件的概率. (2) 分类: 将数据分为几个类别。 (3) 聚类:将数据聚成几个有类似特征的簇 (4)关联规则挖掘:通过对数据之间的关联进行分析，发现其中的潜在规律。 (5) 异常检测:检测数据中的异常值，从而找出潜在的问题 (6) 数据可视化和探索: 通过可视化效果直观地观察数据规律、发掘隐藏的关联，发现新的洞见。</p><h2 id="判断题" tabindex="-1"><a class="header-anchor" href="#判断题" aria-hidden="true">#</a> 判断题</h2><p>1、聚类分析中，聚类所说的簇是事先给定的，是根据数据相似性和距离来划分（）。</p><p>2、两个对象有相同的值，属性值匹配，相似度定义为 0，否则为 1。( )</p><p>3、数护乏掘与传统数据分析方法没有任何区别 ( )</p><div style="color:green;"> 4、信息增益越大说明样本子集越纯，越有利于分类。( ) </div><p>5、ID3 算法不仅可以处理离散属性，还可以处理连续属性。( )</p><p>6、异常就是离群点。( )</p><div style="color:green;"> 7、Ensemble 算法可以通过结合多个弱分类器产生一个强分类器，常见的Ensemble 算法有随机森林和 Adaboost 算法。( ) </div><p>8、关系型的数据库不是数据发掘的对象。( )</p><p>9、贝叶斯分类方法是一种常见的决策树分类方法 ( )</p><div style="color:green;"> 10、熵越小表示样本对目标属性的分布越纯，反之熵越大表示样输出是连续数值（） </div><div style="color:green;"> 1、知识发现是从数据中鉴别出有效模式的非平凡过程。( ) </div><div style="color:green;"> 2、线性相关系数r的值越接近 1或-1，表示两特征的相关性越强;越接近于 0性越弱（）。 </div><p>3、决策树方法通常用于关联规则挖掘（）。</p><p>4、决策树预测数据的过程实质上就是自下而上的。( )</p><p>5、关系型的数据库不是数据挖掘的对象。( )</p><div style="color:green;"> 6、属性是指一个对象的某方面性质或特性。( ) </div><div style="color:green;"> 7、分类和回归都可用于预测，分类的输出是离散的类别值，而回归的输出是是 连续值。( ) </div><p>8、异常点就是离群点。( )</p><p>9、贝叶斯分类方法是一种常见的决策树分类方法 ( )</p><p>10、数据挖掘只能用来分析结构化数据，无法处理非结构化数据。( )</p>',120),e=[s];function g(a,i){return r(),n("div",null,e)}const c=p(t,[["render",g],["__file","数据挖掘.html.vue"]]);export{c as default};
